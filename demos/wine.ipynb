{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules when they change\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c1fdb",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import *\n",
    "from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c766f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = wine_data = load_wine(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f34b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe(), y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ec5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info(), y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d141c4f7",
   "metadata": {},
   "source": [
    "Data exploration: Domain Knowledge, Data Cleaning/Preprocessing, Feature Creation/Construction/Transformation (Sums, Average, Check Existence, Log/Exp), Feature Encoding/Standardization (Scaling, One-Hot-Encodind, Flattening), Feature Selection (Identify Most Relevant Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35254391",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[[\"alcohol\"]], X[[\"ash\"]], c=y, cmap='bwr', edgecolors='k')\n",
    "plt.xlabel(\"Alcohol\")\n",
    "plt.ylabel(\"Ash\")\n",
    "plt.title(\"Wine Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "# X_scaled = pd.DataFrame(min_max_scaler.fit_transform(X_scaled), columns=X.columns)\n",
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0117c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81bae6",
   "metadata": {},
   "source": [
    "Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bd374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42\n",
    ")\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test), len(X_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e750b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = X_train.values.tolist(), X_val.values.tolist(), X_test.values.tolist(), y_train.values.tolist(), y_val.values.tolist(), y_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb60bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]\n",
    "output_dim = y.shape[1]\n",
    "\n",
    "print(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463eecaa",
   "metadata": {},
   "source": [
    "Selecting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91196775",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([\n",
    "    FullyConnected(input_dim, 16, init=RandomNormal(-0.1, 0.1)),\n",
    "    ReLU(),\n",
    "    FullyConnected(16, 32, init=RandomNormal(-0.1, 0.1)),\n",
    "    Dropout(0.2),\n",
    "    ReLU(),\n",
    "    FullyConnected(32, 64, init=RandomNormal(-0.1, 0.1)),\n",
    "    Dropout(0.2),\n",
    "    ReLU(),\n",
    "    FullyConnected(64, output_dim, init=RandomNormal(-0.1, 0.1)),\n",
    "    Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d8f3a",
   "metadata": {},
   "source": [
    "Hyperparameter Turning (Use Cross Validation) \n",
    "* Loss Function\n",
    "* Optimizer (learning_rate, weight_decay, ...)\n",
    "* Number of Epoch\n",
    "* Model Specific (Initializations, Number of Neurons/Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "weight_decay = 0.00\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "metric = Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10a843",
   "metadata": {},
   "source": [
    "Train Model With Best Hyperparameters (Use Cross Validation to Select the Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug block for NN that outputs softmax probabilities\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Take a small batch\n",
    "X_sample = X_train[:5]\n",
    "Y_sample = y_train[:5]  # assume one-hot encoded\n",
    "\n",
    "nn.init_params()\n",
    "\n",
    "# 2. Forward pass (network already outputs softmax probs)\n",
    "Yhat = nn.forward(X_sample)\n",
    "print(\"NN output (softmax probabilities) - first 5 samples:\")\n",
    "for i, row in enumerate(Yhat):\n",
    "    print(f\"Sample {i}: {row}\")\n",
    "\n",
    "# 3. Labels\n",
    "print(\"\\nLabels (first 5 samples):\")\n",
    "for i, row in enumerate(Y_sample):\n",
    "    print(f\"Sample {i}: {row}\")\n",
    "\n",
    "# 4. Compute loss\n",
    "loss_val = loss_fn.loss(Y_sample, Yhat)\n",
    "print(\"\\nLoss value:\", loss_val)\n",
    "\n",
    "# 5. Backward pass (gradient w.r.t softmax outputs)\n",
    "grad = loss_fn.backward()\n",
    "print(\"\\nGradients (first 5 samples):\")\n",
    "for i, row in enumerate(grad[:5]):\n",
    "    print(f\"Sample {i}: {row}\")\n",
    "\n",
    "# 6. Gradient statistics\n",
    "grad_array = np.array(grad)\n",
    "print(\"\\nGradient stats: min =\", grad_array.min(), \n",
    "      \"max =\", grad_array.max(), \n",
    "      \"mean =\", grad_array.mean())\n",
    "\n",
    "# 7. Predicted classes and accuracy\n",
    "y_pred = np.argmax(Yhat, axis=1)\n",
    "y_true = np.argmax(Y_sample, axis=1)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"\\nPredicted classes:\", y_pred)\n",
    "print(\"True classes:     \", y_true)\n",
    "print(\"Validation accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5b97b95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000, Loss: 0.1452, Val Acc: 0.9167\n",
      "Epoch 1000/1000, Loss: 0.1818, Val Acc: 0.9444\n"
     ]
    }
   ],
   "source": [
    "nn.init_params()\n",
    "\n",
    "best_model = None\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    nn.train(X_train, y_train, loss_fn, optimizer)\n",
    "    loss = loss_fn.loss_value\n",
    "\n",
    "    if (epoch + 1) % 100 == 0 or epoch == 0:\n",
    "        prob_distribution = nn.forward(X_val, training=False)\n",
    "        pred_classes = np.array(prob_distribution).argmax(axis=1)\n",
    "        true_classes = np.array(y_val).argmax(axis=1)\n",
    "        val_acc = accuracy_score(true_classes, pred_classes)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = copy.deepcopy(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec1fc6",
   "metadata": {},
   "source": [
    "Evaluate the Model with Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b70b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9444\n",
      "Test F1 Score: 0.9423\n",
      "Test Precision: 0.9514\n",
      "Test Recall: 0.9444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "prob_distribution = best_model.forward(X_test, training=False)\n",
    "pred_classes = np.array(prob_distribution).argmax(axis=1)\n",
    "true_classes = np.array(y_test).argmax(axis=1)\n",
    "accuracy = accuracy_score(true_classes, pred_classes)\n",
    "\n",
    "f1 = f1_score(true_classes, pred_classes, average='weighted')\n",
    "precision = precision_score(true_classes, pred_classes, average='weighted')\n",
    "recall = recall_score(true_classes, pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
